import os
import networkx as nx
import matplotlib.pyplot as plt
from karateclub.node_embedding.neighbourhood import Walklets
from karateclub.graph_embedding import Graph2Vec, GL2Vec
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize, LabelBinarizer
from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix, plot_confusion_matrix, accuracy_score, f1_score, homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score
from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, accuracy_score, homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score
from sklearn import metrics
import time
from wwl import wwl
from sklearn.svm import SVC
import igraph as ig
import argparse
import logging
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
import matplotlib.cm as mplcm
import matplotlib.colors as colors
import seaborn as sns
from sklearn.preprocessing import label_binarize
import pandas as pd
import numpy as np
import pickle
parser = argparse.ArgumentParser()
group = parser.add_mutually_exclusive_group()
group.add_argument("--wwl", help="Use W-WL embeddings",
                    action="store_true")
group.add_argument("--gl2vec", help="Use GL2Vec embeddings",
                    action="store_true")
group.add_argument("--graph2vec", help="Use Graph2Vec embeddings",
                    action="store_true")
parser.add_argument("-d", "--dimensions", help="Feature vector length", type=int)
parser.add_argument("-w", "--wl_iterations", help="Number of WL iterations", type=int)
parser.add_argument("-m", "--min_count", help="Minimal count of graph feature occurrences. Default is 5", type=int, default=5)
parser.add_argument("-rf", "--RF", help="USE RF", action="store_true")
parser.add_argument("-svm", "--SVM", help="USE SVM", action="store_true")




LABELS=["allaple", "browsefox", "expiro", "fireseria", "klez", "mira", "multiplug", "outbrowse", "parite", "softpulse", "sytro", "upatre", "virut", "vobfus", "Singleton"]

def getLabel(file):
	if file.startswith("allaple"):
		return("allaple")
	if file.startswith("browsefox"):
		return("browsefox")
	if file.startswith("expiro"):
		return("expiro")
	if file.startswith("fireseria"):
		return("fireseria")
	if file.startswith("klez"):
	 	return("klez")
	if file.startswith("mira"):
	 	return("mira")
	if file.startswith("multiplug"):
		return("multiplug")
	if file.startswith("outbrowse"):
		return("outbrowse")
	if file.startswith("parite"):
		return("parite")
	if file.startswith("softpulse"):
		return("softpulse")
	if file.startswith("sytro"):
	 	return("sytro")
	if file.startswith("upatre"):
	 	return("upatre")
	if file.startswith("virut"):
		return("virut")
	if file.startswith("vobfus"):
		return("vobfus")
	if file.startswith("Singleton"):
		return("Singleton")


def getMapping(uniqueCallsPath):
	mapping={}
	with open(uniqueCallsPath, "r") as f:
		unique_calls=f.readlines()
	for i in range(len(unique_calls)):
		mapping[unique_calls[i].strip()]=i
	return mapping

def getGraph(path):
	G = nx.read_multiline_adjlist(path=path, create_using=nx.Graph)
	mapping={}
	i=0
	for node in G.nodes():
		#print(G.nodes())
		G.nodes[node]["feature"]=node
		mapping[node]=i
		i=i+1
	G = nx.relabel_nodes(G,mapping)
	return G


def main(args, logger):
	wl_iterations=args.wl_iterations
	dimensions=args.dimensions
	min_count=args.min_count
	if args.graph2vec:
		logger.info("Fit Graph2Vec")
		logger.info("Parameters: dimensions: {}, wl_iterations: {}, min_count: {}".format(dimensions, wl_iterations, min_count))
	if args.gl2vec:
		logger.info("Fit GL2Vec")
		logger.info("Parameters: dimensions: {}, wl_iterations: {}, min_count: {}".format(dimensions, wl_iterations, min_count))
	if args.wwl:
		logger.info("WWL embeddings")
		logger.info("Parameters: wl_iterations: {}".format(wl_iterations))
	
	## 7000 malwares collected from the Malrec Dataset (referenced in Paper) processed into different formats 
	if args.wwl:
		datasetPath="../parsed_og_dataset_gml"
	else:
		datasetPath="../processed_data_7000"
	listFiles=os.listdir(datasetPath)
	start=time.time()
	logger.info("Load Dataset")
	graphDataset=[]
	labels=[]
	for file in listFiles:
		if not file.startswith("Singleton"):
			if args.wwl:
				G=ig.read(os.path.join(datasetPath,file))
			else:
				G=getGraph(os.path.join(datasetPath,file))
			label=getLabel(file)
			labels.append(label)
			graphDataset.append(G)
	end1=time.time()
	logger.info("Done: {}".format(end1-start))

	## Use Deeg Graph Library to extract graph embedding with Graph2vec and/or GL2vec
	if args.graph2vec:
		if os.path.exists('graph2vec_embeddings.pkl'):
			with open('graph2vec_embeddings.pkl', 'rb') as f:
				embeddings = pickle.load(f)
		else:	
			model = Graph2Vec(dimensions=dimensions, wl_iterations=wl_iterations, min_count=min_count)
			model.fit(graphDataset)
			embeddings = model.get_embedding()
			with open('graph2vec_embeddings.pkl', 'wb') as f:
				pickle.dump(embeddings, f)
	if args.gl2vec:
		if os.path.exists('gl2vec_embeddings.pkl'):
			with open('gl2vec_embeddings.pkl', 'rb') as f:
				embeddings = pickle.load(f)
		else:	
			model =  GL2Vec(dimensions=dimensions, wl_iterations=wl_iterations, min_count=min_count)
			model.fit(graphDataset)
			embeddings = model.get_embedding()
			with open('gl2vec_embeddings.pkl', 'wb') as f:
				pickle.dump(embeddings, f)
	if args.wwl:
		embeddings=wwl(graphDataset, num_iterations=wl_iterations)
	#
	end2=time.time()
	logger.info("Model fit time: {}".format(end2-end1))
	
	#logger.info(labels)
	X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=1)

	logger.info("Training data: {}".format(X_train.shape))
	logger.info("Testing data: {}".format(X_test.shape))
	for i in range(14):
		logger.info(f"y_train[{i+1}]: {y_train[i]}")
		logger.info(f"y_train[{i+1}] count: {y_train.count(y_train[i])}")
		logger.info(f"y_train[{i+1}] pct: {(y_train.count(y_train[i])/len(y_train))}")

	logger.info("Fit Classifier\n")
	start=time.time()
	
	#### Train Random Forest or SVM for downstream classification
	if args.RF:
		classifier = RandomForestClassifier(n_estimators=1500, random_state=0, n_jobs=20)
	if args.SVM:
		classifier = SVC(kernel='linear', probability=True, random_state=0)
	
	classifier.fit(X_train,y_train)
	end1=time.time()
	logger.info("Done: {}".format(end1-start))
	#########
	classes = list(set(y_train))
	classes.sort()
	n_classes = len(classes)
	y_test_bin = label_binarize(y_test, classes=classes) 
	#########

	y_pred=classifier.predict(X_test)
	if args.RF:
		y_proba = classifier.predict_proba(X_test)
	if args.SVM:
		y_proba = classifier.decision_function(X_test)

	logger.info(confusion_matrix(y_test,y_pred))

	logger.info(classification_report(y_test,y_pred))

	logger.info(accuracy_score(y_test, y_pred))


##########################################
# 	#### Getting results and creating plots
	if args.SVM:
		classifier_name="SVM"
	if args.RF:
		classifier_name="RF"
	if args.graph2vec:
		output = "Report_Graph2vec"
		method = 'Graph2Vec'
	if args.gl2vec:
		output = "Report_GL2vec"
		method = 'GL2Vec'
	if not os.path.exists(output):
		os.mkdir(output)
	cm = plt.get_cmap('tab20')
	cNorm = colors.Normalize(vmin=0, vmax=n_classes)
	scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)

	print(f"Creating ROC curve for {classifier_name}...   ", end="\r")

	_, ax = plt.subplots()
	ax.set_prop_cycle(color=[scalarMap.to_rgba(i) for i in range(n_classes)])
	fpr, tpr, roc_auc = dict(), dict(), dict()
	for i in range(n_classes):
		fpr[i], tpr[i], _ = metrics.roc_curve(y_test_bin[:, i], y_proba[:, i])
		roc_auc[i] = metrics.auc(fpr[i], tpr[i])
		plt.plot(fpr[i], tpr[i], lw=1, label='%s ROC curve (area = %0.4f)' % (classes[i].title(), roc_auc[i]))
	plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')
	plt.xlim([0.0, 1.0])
	plt.ylim([0.0, 1.05])
	plt.xlabel('False Positive Rate')
	plt.ylabel('True Positive Rate')
	fpr["avg"], tpr["avg"], _ = metrics.roc_curve(y_test_bin.ravel(), y_proba.ravel())
	roc_auc["avg"] = metrics.auc(fpr["avg"], tpr["avg"])
	plt.plot(fpr["avg"], tpr["avg"], lw=2, label='Avg ROC curve (area = %0.4f)' % (roc_auc["avg"]))
	h, l = ax.get_legend_handles_labels()
	handles, labels = [], []
	hl = sorted(zip(l, h))
	idx_avg = 0
	for idx, asdf in enumerate(hl):
		if asdf[0][:13] == "Avg ROC curve":
			idx_avg = idx
			continue
		handles.append(asdf[1])
		labels.append(asdf[0])
	handles.append(hl[idx_avg][1])
	labels.append(hl[idx_avg][0])

	plt.title(f"{method}, ROC AUC Curves")
	lgd = plt.legend(handles, labels, title='Legend', bbox_to_anchor=(1.05, 1), loc="best")
	plt.savefig(os.path.join(output, f"ROC_{classifier_name}.png"), bbox_extra_artists=(lgd,), bbox_inches='tight')
	print(f"Creating confusion matrix for {classifier_name}...", end="\r")
	fig, ax = plt.subplots(figsize=(8,8))
	metrics.plot_confusion_matrix(classifier, X_test, y_test, cmap=plt.cm.YlOrRd, normalize='true', ax=ax)
	plt.title(f"{method}, Confusion Matrix")
	_, labels = plt.xticks()
	plt.setp(labels, rotation=40, horizontalalignment='right')
	plt.tight_layout()
	plt.savefig(os.path.join(output, f"CM_{classifier_name}.png"))

	print(f"Plotting AVG ROC curve for {classifier_name}...", end="\r")
	plt.figure()
	plt.xlim([0.0, 1.0])
	plt.ylim([0.0, 1.05])
	plt.xlabel('False Positive Rate')
	plt.ylabel('True Positive Rate')
	plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')
	#plt.plot(fpr["avg"], tpr["avg"], color='red', lw=2, label='Avg ROC curve (area = %0.4f)' % (roc_auc["avg"]))
	plt.plot(fpr["avg"], tpr["avg"], color='red', lw=2, label=f'Avg ROC AUC = {roc_auc["avg"]*100:.2f}%')
	plt.legend(loc='lower right', shadow=True, fontsize='large')
	#plt.title("SVM: "+", ".join(title).title())
	plt.title(f"{method}: Average ROC")
	plt.savefig(os.path.join(output, f"ROCAVG_{classifier_name}.png"))

	print(f"Creating classification report for {classifier_name}...", end="\r")
	cr = metrics.classification_report(y_test, y_pred, digits=3, output_dict=True, zero_division=0)
	plt.figure()
	sns.heatmap(pd.DataFrame(cr).iloc[:-1,:].T, annot=True)
	plt.title(f"{method}, Classification Report")
	plt.tight_layout()
	plt.savefig(os.path.join(output, f"CR_{classifier_name}.png"))

	with open(os.path.join(output, "Classification Report.txt"),"w") as f:
		f.write(np.array2string(metrics.confusion_matrix(y_test,y_pred)))
		f.write("\n")
		f.write(metrics.classification_report(y_test,y_pred))
		f.write("\n")
		f.write(metrics.classification_report(y_test,y_pred, digits=4))






if __name__ == "__main__":
	args = parser.parse_args()
	logging.basicConfig(
		level=logging.INFO,
		#filename='{}_{:02d}.log'.format(args.dataset, args.num_iterations)
	)
	logger = logging.getLogger('GraphEmbedding')
	logger.propagate = False
	# Create a second stream handler for logging to `stderr`, but set
	# its log level to be a little bit smaller such that we only have
	# informative messages
	stream_handler = logging.StreamHandler()
	stream_handler.setLevel(logging.INFO)
	# Use the default format; since we do not adjust the logger before,
	# this is all right.
	stream_handler.setFormatter(logging.Formatter(logging.BASIC_FORMAT))
	logger.addHandler(stream_handler)
	main(args, logger)


